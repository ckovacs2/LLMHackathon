# Data Ingestion

This directory utilities to fetch **materials data** from the [Materials Project](https://materialsproject.org/) API and store it in structured formats for downstream analysis.

The script collects:

- **Stable, non-deprecated materials metadata** ‚Üí saved as `materials.parquet`
- **Density of States (DOS)** ‚Üí saved as `dos_data.h5`
- **CIF structures** ‚Üí saved as `cifs.zip`

It also includes utilities for diagnostics and CIF access from the compressed archive.

---

## üì¶ Requirements

- Python 3.9+
- [Materials Project API key](https://next-gen.materialsproject.org/api)  
  (set it as an environment variable `MP_API_KEY` or store in a `.env` file)

Install dependencies:

```bash
pip install mp-api pandas h5py tqdm python-dotenv
```

Optional (if using analysis with pymatgen):
```bash
pip install pymatgen
```

## üöÄ Usage

Run the script directly:
```bash
python mp_fetch.py
```

It will:
1. Fetch stable materials (materials.parquet)
2. Collect DOS data (dos_data.h5)
3. Collect CIFs (cifs.zip)
4. Print diagnostics (file sizes, entry counts)
5. Show the first 5 materials

## üìÇ Output Files

| File               | Format | Contents                                                                 |
|--------------------|--------|--------------------------------------------|
| `materials.parquet` | Parquet | Table of stable, non-deprecated materials (IDs, formula, spacegroup, density, band gap, etc.) |
| `dos_data.h5`       | HDF5   | Fermi levels, energy grid, densities, and DOS@E_F for each material with DOS data |
| `cifs.zip`          | Zip    | CIF files, one per material ID                                           |


## üõ†Ô∏è Utilities
**File Diagnostics**

The script logs the size and content count of each dataset:
* Row count in materials.parquet
* Group count in dos_data.h5
* File count in cifs.zip

Example output:
```pgsql
INFO: Materials file: materials.parquet size = 11.43 KB
INFO: DOS file: dos_data.h5 size = 2.79 MB (80 groups)
INFO: CIFs file: cifs.zip size = 310.00 KB (100 files)
```

**Reading CIFs From Zip**

You can read CIFs without extracting:

```python
from mp_fetch import read_cif_from_zip, DATA_DIR

zip_path = DATA_DIR / "cifs.zip"

# Single material
cif_str = read_cif_from_zip(zip_path, "mp-149")

# List of materials
cifs = read_cif_from_zip(zip_path, ["mp-149", "mp-13"])

# All CIFs
all_cifs = read_cif_from_zip(zip_path, None)
```

Returns either a single CIF string or a dictionary ```{material_id: cif_string}```.

## ‚ö° Notes

Not all materials have DOS or CIF data.

To guarantee consistency, you can filter datasets to the intersection of IDs across `materials.parquet`, `dos_data.h5`, and `cifs.zip`.

API calls can take time; outputs are cached and reused unless deleted.
